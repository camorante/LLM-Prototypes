{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48710988-44c3-490c-895f-e38981c07fe8",
   "metadata": {},
   "source": [
    "# LLM Development - SQL Agent With Chain\n",
    "\n",
    "![](images/llmsql.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97147d0-1d0e-494d-b576-b6e8a5661138",
   "metadata": {},
   "source": [
    "<h2 style=\"color:Blue\">General Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf55de9-f4b8-4ddc-826f-3ed8a278175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import getpass\n",
    "from sqlalchemy import exc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27024fed-f873-45b3-9855-5832443c4ab6",
   "metadata": {},
   "source": [
    "<h2 style=\"color:Blue\">Langchain Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aba13b8b-319f-410a-a108-8766919807a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.llms import Ollama\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032886b6-0dcf-493f-9a76-638fda5d3d6c",
   "metadata": {},
   "source": [
    "<h2 style=\"color:Blue\">Pre-Loadings</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998a4f58-8b20-4045-ac18-1668fc35d6d9",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Green\">Question and Vars</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da1e48dd-13a0-4cce-978c-12b71df54dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\n",
    "rag_model_id = 4\n",
    "sql_model_id = 4\n",
    "temperature = 0\n",
    "keep_alive = 250\n",
    "num_predict = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7503ed-bfde-42ef-ba56-49bfa60dfe44",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Green\">Model Selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a35a8fa7-d1fe-4640-aed8-47a4d6c68ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(id):\n",
    "    if id == 1:\n",
    "        return \"hf.co/SanctumAI/Meta-Llama-3.1-8B-Instruct-GGUF:Q6_K\"\n",
    "    elif id == 2:\n",
    "        return \"mistral-nemo:latest\"\n",
    "    elif id == 3:\n",
    "        return \"codestral:latest\"\n",
    "    elif id == 4:\n",
    "        return \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af538b5f-f3ab-48e5-8549-7fac3eb3f370",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Green\">Keys</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c2323f4-a7d4-45ca-bb06-b58825c5634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = open(\"key.txt\", \"r\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = key.read()\n",
    "key.close()\n",
    "\n",
    "key = open(\"keyls.txt\", \"r\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"gpstrackit-dev\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = key.read()\n",
    "key.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4018a0-c505-4880-b9ce-c69d428255e7",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Green\">LLM Instance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddd4a097-2949-4882-a489-130cc3b66686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000233B9445510>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000233B9455B40>, root_client=<openai.OpenAI object at 0x00000233B93EB190>, root_async_client=<openai.AsyncOpenAI object at 0x00000233B94458A0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if sql_model_id == 4:\n",
    "    llm = ChatOpenAI(model=get_model(sql_model_id), temperature = temperature)\n",
    "else: \n",
    "    llm = ChatOllama(model=get_model(sql_model_id), num_predict = num_predict, keep_alive = keep_alive, temperature = temperature)\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f8ff7-c6a8-475a-97b4-d0ceef87e980",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Green\">Database Connections</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "835baa9e-b291-4269-b114-b8b13d3ebffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'Penelope', 'Guiness', datetime.datetime(2013, 5, 26, 14, 47, 57, 620000))]\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_url = \"postgresql+psycopg2://llmuser:123456789@localhost:5432/dvdrental\"\n",
    "db = SQLDatabase.from_uri(database_url)\n",
    "db.run(\"SELECT * FROM public.actor ORDER BY actor_id ASC limit 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d3d25-b094-47f5-bcf5-cb3bb582332d",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Green\">Chain Instance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76b27060-32e1-498e-b9dd-87a4316b67a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_sql_query_chain(llm, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe84d3-1518-497c-abf0-5aaa18bfd579",
   "metadata": {},
   "source": [
    "<h2 style=\"color:Blue\">Prompts Execs</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a96089-f25f-4bdd-9e48-c0c7ea1c250a",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Green\">Prompt Orders</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "894738a2-28a3-4dd2-8b82-caa06f060feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a PostgreSQL expert. Given an input question, first create a syntactically correct PostgreSQL query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per PostgreSQL. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use CURRENT_DATE function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain.get_prompts()[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58cb6f25-229c-4005-b7a1-b6973b94b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "    return db.run(extract_sql(query))\n",
    "\n",
    "def extract_sql(text):\n",
    "    print(type(text))\n",
    "    sql = text[\"query\"]\n",
    "    print(sql)\n",
    "    words_to_remove = [\"SQLQuery:\", \"sql\"]\n",
    "    for word_to_remove in words_to_remove:\n",
    "        sql = sql.replace(word_to_remove, \"\")\n",
    "    sql = sql[sql.find(\"SELECT\"): sql.find(\";\")]\n",
    "    print(sql)\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986e9f2-bf63-4cf7-b681-2d497dbe1568",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Green\">Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc3ffa1b-d4ec-4d73-bee0-1c77e5074a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SQLQuery: SELECT COUNT(\"film_id\") AS total_films FROM film;'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'cuantas peliculas hay en la base de datos'\n",
    "response = chain.invoke({\"question\": question})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "457e304b-4092-48ad-807b-b71777ef380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "SQLQuery: SELECT COUNT(\"film_id\") AS \"total_peliculas\" FROM film;\n",
      "SELECT COUNT(\"film_id\") AS \"total_peliculas\" FROM film\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hay 1000 películas en la base de datos.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question in spanish.\n",
    "    \n",
    "    Question: {question}\n",
    "    SQL Query: {query}\n",
    "    SQL Result: {result}\n",
    "    Answer: \"\"\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough\n",
    "        .assign(query=write_query)\n",
    "        .assign(\n",
    "            result=extract_sql | execute_query\n",
    "        )\n",
    "    | answer_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc36e6-31b5-46a9-81df-044601f672a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
